{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.7 64-bit",
   "display_name": "Python 3.7.7 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "5d87b42201e74ac320bc00dce267d44f5f134edfec9046f67f672f289707ff6a"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Group Chat Analysis System\n",
    "Merupakan suatu sistem untuk menganalisa suatu pesan di dalam group apakah termasuk pesan yang baik, buruk, benar, atau hoax. Dengan analisa tersebut, nantinya dapat disimpulkan bahwa semakin tinggi dan banyak pesan yang teranalisa buruk atau hoax maka group tersebut dapat dipastikan adalah group yang tidak benar. Dan sebaliknya, jika di dalam grup tersebut banyak pesan baik dan informasi yang disampaikan adalah benar, maka dapat disimpulkan bahwa group tersebut adalah group yang baik.\n",
    "\n",
    "Sistem ini disusun oleh\n",
    "\n",
    "- Fitri Amalia Langgundi\n",
    "- Khoerul Umam\n",
    "- Muhammad Ikhsan Hadi\n",
    "- Rozak Ilham Aditya\n",
    "\n",
    "Dalam mata kuliah : Sistem Pakar"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Group Chat Analysis \n",
    "Inisalisasi library yang dibutuhkan. Beberapa library yang digunakan diantaranya, library untuk memfilter pesan, library untuk mengolah link, library untuk mengolah dataset, library untuk menentukan tingkat karakteristik pesan, dan library lain akan ditambahkan seiring dengan bertambahnya kompleksitas sistem"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tldextract\n",
    "import pandas as pd\n",
    "import jellyfish as jelly\n",
    "import numpy as np"
   ]
  },
  {
   "source": [
    "#### Inisialisai Class\n",
    "Class yang digunakan diberi nama class Pakar. Di dalamnya terdapat berbagai fungsi yang akan memproses data pesan sehingga dapat diketahui karakteristik pesan tersebut. Saat ini sistem hanya dapat memproses satu per satu pesan."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pakar:\n",
    "    def __init__ (self):\n",
    "        self.text = ''\n",
    "        self.link = []\n",
    "        self.domaindataset = pd.read_csv('D:\\Project\\Self\\Pakar\\domain.csv', skiprows=0)\n",
    "        self.result = []\n",
    "\n",
    "    def process(self, text):\n",
    "        self.text = text\n",
    "        self.checkLink()\n",
    "        self.checkText()\n",
    "\n",
    "    def checkLink(self):\n",
    "        regex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "        url = re.findall(regex,self.text)       \n",
    "        for x in url:\n",
    "            link = x[0]\n",
    "            domain = tldextract.extract(x[0])\n",
    "            suffix = domain.suffix\n",
    "\n",
    "            if (domain.suffix == ''):\n",
    "                suffix = domain.domain\n",
    "            \n",
    "            checkDomain = self.domaindataset.loc[self.domaindataset['Domain'] == '.' + suffix]\n",
    "                \n",
    "            if (link.find('https') != -1):\n",
    "                # if self.domaindataset['Domain'].str.contains(suffix).any():\n",
    "                if (checkDomain.empty == False):\n",
    "                    self.link.append([link, 'Aman', checkDomain['Domain'].values, checkDomain['Type'].values, checkDomain['Sponsoring Organisation'].values])\n",
    "                    # np.append([link, 'safe'], self.link)\n",
    "                else:\n",
    "                    # np.append([link, 'sus'], self.link)\n",
    "                    self.link.append([link, 'Mencurigakan', checkDomain['Domain'].values, checkDomain['Type'].values, checkDomain['Sponsoring Organisation'].values])\n",
    "            else:\n",
    "                # if self.domaindataset['Domain'].str.contains(suffix).any():\n",
    "                if (checkDomain.empty == False):\n",
    "                    # np.append([link, 'low security'], self.link)\n",
    "                    self.link.append([link, 'Keamanan Lemah', checkDomain['Domain'].values, checkDomain['Type'].values, checkDomain['Sponsoring Organisation'].values])\n",
    "                else:\n",
    "                    self.link.append([link, 'Bahaya', checkDomain['Domain'].values, checkDomain['Type'].values, checkDomain['Sponsoring Organisation'].values])\n",
    "                    # np.append([link, 'danger'], self.link)\n",
    "\n",
    "    def checkText(self):\n",
    "        dataset = pd.read_csv('D:\\Project\\Self\\Pakar\\hoax.csv', header=None)\n",
    "        for index, row in dataset.iterrows():\n",
    "            self.result.append([index, jelly.jaro_distance(self.text, row[0])])\n",
    "            # np.append([index, jelly.levenshtein_distance(self.text, row[0])], self.result)\n",
    "        self.result = sorted(self.result, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    def get_domain_dt(self):\n",
    "        return self.domaindataset\n",
    "    \n",
    "    def get_result(self):\n",
    "        return self.result\n",
    "\n",
    "    def show_result(self):\n",
    "        print('Tingkat ke-hoax-an pesan: ', self.result[0][1], '\\n')\n",
    "        if (self.link != None):\n",
    "            for x in self.link:\n",
    "                print('Link: ', x[0], ' terindikasi ', x[1], '\\n')\n",
    "                print('Domain: ', x[2], '\\n')\n",
    "                print('Tipe Link: ', x[3], '\\n')\n",
    "                print('Keterangan: ', x[4], '\\n\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "### Testing\n",
    "Testing digunakan per pesan. Dilakukan seperti di bawah ini, pesan akan diketahui seberapa dekat karakteristik dengan dataset yang digunakan, termasuk jika ada link di dalamnya, akan di ketahui link mana yang berbahaya dan link mana yang aman."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tingkat ke-hoax-an pesan:  0.7004830917874396 \n\nLink:  http://umam.keren  terindikasi  Bahaya \n\nDomain:  [] \n\nTipe Link:  [] \n\nKeterangan:  [] \n\n\nLink:  https://google.com  terindikasi  Aman \n\nDomain:  ['.com'] \n\nTipe Link:  ['generic'] \n\nKeterangan:  ['VeriSign Global Registry Services'] \n\n\n"
     ]
    }
   ],
   "source": [
    "t = Pakar()\n",
    "t.process('bang sate dapat dibeli di http://umam.keren dan di https://google.com')\n",
    "t.show_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}